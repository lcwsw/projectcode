{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0ae379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: nltk in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (1.3.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (2023.10.3)\r\n",
      "Requirement already satisfied: tqdm in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8e724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ching/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/ching/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f621182",
   "metadata": {},
   "source": [
    "## Excluding Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbe855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "stars: 235\n",
      "phone: 111\n",
      "great: 105\n",
      "good: 96\n",
      "sound: 94\n",
      "speaker: 77\n",
      "gift: 68\n",
      "use: 52\n",
      "works: 46\n",
      "product: 41\n",
      "\n",
      "Top Negative Keywords:\n",
      "stars: 123\n",
      "phone: 58\n",
      "speaker: 44\n",
      "sound: 40\n",
      "would: 29\n",
      "great: 27\n",
      "work: 26\n",
      "stand: 25\n",
      "use: 24\n",
      "product: 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"3_lxyuan_distilbert_processed_less.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter positive and negative reviews\n",
    "positive_reviews = df[df['Sentiment_Label'] == 'positive']['Preprocessed_Body']\n",
    "negative_reviews = df[df['Sentiment_Label'] == 'negative']['Preprocessed_Body']\n",
    "\n",
    "# Tokenization and stopwords removal\n",
    "def process_reviews(reviews):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews)\n",
    "negative_tokens = process_reviews(negative_reviews)\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Identify top keywords\n",
    "top_positive_keywords = positive_freq.most_common(10)\n",
    "top_negative_keywords = negative_freq.most_common(10)\n",
    "\n",
    "# Print Top Keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for keyword, frequency in top_positive_keywords:\n",
    "    print(f\"{keyword}: {frequency}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for keyword, frequency in top_negative_keywords:\n",
    "    print(f\"{keyword}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f16694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('stars', 'great'): 33\n",
      "('stars', 'good'): 24\n",
      "('sound', 'quality'): 21\n",
      "('good', 'sound'): 17\n",
      "('works', 'great'): 14\n",
      "('easy', 'use'): 13\n",
      "('phone', 'stand'): 12\n",
      "('stars', 'works'): 12\n",
      "('works', 'well'): 12\n",
      "('great', 'sound'): 12\n",
      "\n",
      "Top Negative Keywords:\n",
      "('stopped', 'working'): 14\n",
      "('waste', 'money'): 10\n",
      "('money', 'stars'): 9\n",
      "('phone', 'stand'): 8\n",
      "('cell', 'phone'): 7\n",
      "('worth', 'money'): 6\n",
      "('stars', 'work'): 6\n",
      "('sound', 'quality'): 6\n",
      "('stars', 'stopped'): 6\n",
      "('work', 'stars'): 5\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    n_grams = list(ngrams(filtered_tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=2)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=2)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b1a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('good', 'sound', 'quality'): 6\n",
      "('stars', 'good', 'product'): 5\n",
      "('stars', 'works', 'great'): 5\n",
      "('stars', 'great', 'product'): 5\n",
      "('stars', 'great', 'sound'): 5\n",
      "('stars', 'great', 'gift'): 4\n",
      "('stars', 'good', 'value'): 4\n",
      "('nice', 'gift', 'stars'): 3\n",
      "('cell', 'phone', 'stand'): 3\n",
      "('father', 'day', 'gift'): 3\n",
      "('stars', 'gift', 'gift'): 3\n",
      "('stars', 'husband', 'loves'): 3\n",
      "('stars', 'bought', 'gift'): 3\n",
      "('product', 'would', 'recommend'): 3\n",
      "('stars', 'works', 'well'): 3\n",
      "('stars', 'good', 'sound'): 3\n",
      "('easy', 'use', 'stars'): 3\n",
      "('worth', 'money', 'stars'): 3\n",
      "('good', 'value', 'money'): 3\n",
      "('stars', 'nice', 'little'): 2\n",
      "\n",
      "Top Negative Keywords:\n",
      "('waste', 'money', 'stars'): 6\n",
      "('stars', 'stopped', 'working'): 6\n",
      "('cell', 'phone', 'stand'): 4\n",
      "('stopped', 'working', 'months'): 4\n",
      "('poor', 'sound', 'quality'): 3\n",
      "('volume', 'waste', 'money'): 2\n",
      "('phone', 'stand', 'speaker'): 2\n",
      "('thin', 'case', 'sure'): 2\n",
      "('case', 'sure', 'would'): 2\n",
      "('stars', 'worth', 'money'): 2\n",
      "('stars', 'disappointed', 'thought'): 2\n",
      "('could', 'barely', 'hear'): 2\n",
      "('speaker', 'takes', 'space'): 2\n",
      "('takes', 'space', 'cell'): 2\n",
      "('latency', 'bluetooth', 'speakers'): 2\n",
      "('type', 'c', 'cable'): 2\n",
      "('unit', 'died', 'next'): 2\n",
      "('died', 'next', 'day'): 2\n",
      "('next', 'day', 'last'): 2\n",
      "('day', 'last', 'day'): 2\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    n_grams = list(ngrams(filtered_tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=3)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=3)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aa1fd",
   "metadata": {},
   "source": [
    "## Including Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924fa282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('for', 'the', 'price'): 15\n",
      "('as', 'a', 'gift'): 15\n",
      "('easy', 'to', 'use'): 13\n",
      "('the', 'sound', 'is'): 11\n",
      "('i', 'bought', 'this'): 11\n",
      "('gift', 'for', 'my'): 10\n",
      "('this', 'for', 'my'): 10\n",
      "('this', 'as', 'a'): 10\n",
      "('a', 'gift', 'for'): 10\n",
      "('this', 'was', 'a'): 9\n",
      "('the', 'sound', 'quality'): 9\n",
      "('bought', 'this', 'for'): 9\n",
      "('for', 'my', 'husband'): 9\n",
      "('in', 'the', 'kitchen'): 8\n",
      "('this', 'is', 'a'): 7\n",
      "('i', 'use', 'it'): 7\n",
      "('sound', 'quality', 'is'): 7\n",
      "('he', 'loves', 'it'): 7\n",
      "('bought', 'this', 'as'): 7\n",
      "('stars', 'great', 'for'): 6\n",
      "\n",
      "Top Negative Keywords:\n",
      "('waste', 'of', 'money'): 7\n",
      "('stopped', 'working', 'after'): 7\n",
      "('this', 'for', 'my'): 6\n",
      "('worth', 'the', 'money'): 6\n",
      "('to', 'use', 'it'): 6\n",
      "('did', 'not', 'work'): 6\n",
      "('not', 'worth', 'it'): 6\n",
      "('it', 'stopped', 'working'): 6\n",
      "('it', 'doesn', 't'): 5\n",
      "('not', 'worth', 'the'): 5\n",
      "('to', 'my', 'phone'): 5\n",
      "('stars', 'stopped', 'working'): 5\n",
      "('cell', 'phone', 'stand'): 4\n",
      "('as', 'loud', 'as'): 4\n",
      "('if', 'you', 'are'): 4\n",
      "('i', 'thought', 'it'): 4\n",
      "('it', 's', 'not'): 4\n",
      "('my', 'phone', 'and'): 4\n",
      "('bought', 'this', 'for'): 4\n",
      "('doesn', 't', 'work'): 4\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=3)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=3)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb27c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
