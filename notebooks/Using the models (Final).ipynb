{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4726b28",
   "metadata": {},
   "source": [
    "# Differnt Models on both proccesed and preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cf8a35d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - huggingface\n",
      " - pytorch\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: huggingface-hub in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg (0.19.0)\n",
      "Requirement already satisfied: filelock in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (2023.9.2)\n",
      "Requirement already satisfied: requests in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from huggingface-hub) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from requests->huggingface-hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from requests->huggingface-hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from requests->huggingface-hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!echo \"y\" | conda install -c huggingface transformers -y\n",
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c381a1da-3012-402d-9917-839fc99f1fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - pytorch\n",
      " - defaults\n",
      " - huggingface\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install packages using Conda\n",
    "!echo \"y\" |conda install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf41973-16fe-4125-b622-6cab866a3df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chardet in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (5.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch \n",
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548b6f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: openpyxl in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (3.1.2)\r\n",
      "Requirement already satisfied: et-xmlfile in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from openpyxl) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acba3ce",
   "metadata": {},
   "source": [
    "## 1st LiYuan/amazon-review-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a9e35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Preprocessed_Body  Sentiment_Label  \\\n",
      "0    5 stars nice little bluetooth box bought for a...              4.0   \n",
      "1    5 stars easy to operate .. the product was ama...              4.0   \n",
      "2    5 stars love my jteman cell phone holder i sim...              4.0   \n",
      "3    5 stars great buy on sale solid easy to use an...              4.0   \n",
      "4    5 stars this is a gift he loves listening to m...              4.0   \n",
      "..                                                 ...              ...   \n",
      "370  1 stars chinese spy device my wife got me this...              0.0   \n",
      "371  1 stars received as a gift dead out of the box...              0.0   \n",
      "372  1 stars horrible im beyond late on this review...              0.0   \n",
      "373  1 stars defective audio issue i got this as a ...              0.0   \n",
      "374  1 stars will not charge i thought this was sup...              0.0   \n",
      "\n",
      "     Max_Sentiment_Score  \n",
      "0               0.975006  \n",
      "1               0.987549  \n",
      "2               0.989188  \n",
      "3               0.993481  \n",
      "4               0.990091  \n",
      "..                   ...  \n",
      "370             0.967510  \n",
      "371             0.980290  \n",
      "372             0.984328  \n",
      "373             0.967772  \n",
      "374             0.979149  \n",
      "\n",
      "[375 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"LiYuan/amazon-review-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load your preprocessed data from the CSV file\n",
    "df = pd.read_csv('preprocessed_data_veryless.csv')\n",
    "\n",
    "# Function to predict sentiment using the model\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    sentiment_score = torch.softmax(logits, dim=1).tolist()[0]  # Get the sentiment score\n",
    "    return predicted_class, max(sentiment_score)  # Keep only the maximum sentiment score\n",
    "\n",
    "# Apply the sentiment prediction to the 'Preprocessed_Body' column\n",
    "df[['Sentiment_Label', 'Max_Sentiment_Score']] = df['Preprocessed_Body'].apply(predict_sentiment).apply(pd.Series)\n",
    "\n",
    "# Display the DataFrame with the new 'Sentiment_Label' and 'Max_Sentiment_Score' columns\n",
    "print(df[['Preprocessed_Body', 'Sentiment_Label', 'Max_Sentiment_Score']])\n",
    "\n",
    "# Save the DataFrame with sentiment labels and scores to a new CSV file\n",
    "df.to_csv('1_sentiment_analysis_results_processed_less.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dca8ea6",
   "metadata": {},
   "source": [
    "## 2nd nlptown/bert-base-multilingual-uncased-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c28c4ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Preprocessed_Body  Sentiment_Label  \\\n",
      "0    5 stars nice little bluetooth box bought for a...              4.0   \n",
      "1    5 stars easy to operate .. the product was ama...              4.0   \n",
      "2    5 stars love my jteman cell phone holder i sim...              4.0   \n",
      "3    5 stars great buy on sale solid easy to use an...              4.0   \n",
      "4    5 stars this is a gift he loves listening to m...              4.0   \n",
      "..                                                 ...              ...   \n",
      "370  1 stars chinese spy device my wife got me this...              0.0   \n",
      "371  1 stars received as a gift dead out of the box...              0.0   \n",
      "372  1 stars horrible im beyond late on this review...              0.0   \n",
      "373  1 stars defective audio issue i got this as a ...              0.0   \n",
      "374  1 stars will not charge i thought this was sup...              0.0   \n",
      "\n",
      "     Sentiment_Score  \n",
      "0           0.889987  \n",
      "1           0.973634  \n",
      "2           0.985940  \n",
      "3           0.991592  \n",
      "4           0.985782  \n",
      "..               ...  \n",
      "370         0.787746  \n",
      "371         0.963464  \n",
      "372         0.984079  \n",
      "373         0.920723  \n",
      "374         0.963809  \n",
      "\n",
      "[375 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import openpyxl\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load your preprocessed data from the CSV file\n",
    "df = pd.read_csv('preprocessed_data_veryless.csv')\n",
    "\n",
    "# Function to predict sentiment using the model\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    sentiment_score = torch.softmax(logits, dim=1).max().item()  # Get the highest sentiment score\n",
    "    return predicted_class, sentiment_score\n",
    "\n",
    "# Apply the sentiment prediction to the 'Preprocessed_Body' column\n",
    "df[['Sentiment_Label', 'Sentiment_Score']] = df['Preprocessed_Body'].apply(predict_sentiment).apply(pd.Series)\n",
    "\n",
    "# Display the DataFrame with the new 'Sentiment_Label' and 'Sentiment_Score' columns\n",
    "print(df[['Preprocessed_Body', 'Sentiment_Label', 'Sentiment_Score']])\n",
    "\n",
    "# Save the DataFrame with sentiment labels and scores to a new CSV file\n",
    "df.to_csv('2_bert-base-multilingual-uncased-sentiment_processed_less.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c6bbd0",
   "metadata": {},
   "source": [
    "## 3rd lxyuan/distilbert-base-multilingual-cased-sentiments-student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ce5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load the sentiment analysis pipeline with the specified model\n",
    "classifier_distilbert = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
    "\n",
    "# Load your CSV file into a DataFrame (replace 'your_file.csv' with your actual file path)\n",
    "df = pd.read_csv('preprocessed_data_veryless.csv')\n",
    "\n",
    "# Create empty lists to store labels and scores\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Process each review and store the results\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Preprocessed_Body']  # Assuming 'Body' is the column containing the reviews\n",
    "    try:\n",
    "        # Truncate the text to the maximum sequence length\n",
    "        truncated_text = text[:512]\n",
    "        result = classifier_distilbert(truncated_text)[0]  # Assuming you only want the first result if multiple are returned\n",
    "        labels.append(result['label'])\n",
    "        scores.append(result['score'])\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped review at index {index} due to error: {e}\")\n",
    "        labels.append('unknown')\n",
    "        scores.append('unknown')\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['Sentiment_Label'] = labels\n",
    "df['Sentiment_Score'] = scores\n",
    "\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "df.to_csv('3_lxyuan_distilbert_processed_less.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71b49f",
   "metadata": {},
   "source": [
    "## 4th sohan-ai/sentiment-analysis-model-amazon-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70c3f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped review at index 101 due to error: The size of tensor a (689) must match the size of tensor b (512) at non-singleton dimension 1\n",
      "Skipped review at index 116 due to error: The size of tensor a (559) must match the size of tensor b (512) at non-singleton dimension 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the fine-tuned model from Hugging Face\n",
    "model_name = \"sohan-ai/sentiment-analysis-model-amazon-reviews\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Load your CSV file into a DataFrame (replace 'your_file.csv' with your actual file path)\n",
    "df = pd.read_csv('preprocessed_data_veryless.csv')\n",
    "\n",
    "# Create empty lists to store labels and scores\n",
    "labels = []\n",
    "scores = []\n",
    "\n",
    "# Process each review and store the results\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Preprocessed_Body']  # Assuming 'Body' is the column containing the reviews\n",
    "    try:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "        predicted_label = \"positive\" if outputs.logits.argmax().item() == 1 else \"negative\"\n",
    "        labels.append(predicted_label)\n",
    "        scores.append(outputs.logits.softmax(dim=1).max().item())\n",
    "    except Exception as e:\n",
    "        print(f\"Skipped review at index {index} due to error: {e}\")\n",
    "        labels.append('unknown')\n",
    "        scores.append('unknown')\n",
    "\n",
    "# Add new columns to the DataFrame\n",
    "df['Sentiment_Label'] = labels\n",
    "df['Sentiment_Score'] = scores\n",
    "\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "df.to_csv('4_sohan_ai_sentiment_analysis_processed_less.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7e222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Channels:\n",
      " - conda-forge\n",
      " - pytorch\n",
      " - defaults\n",
      " - huggingface\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/ching/miniconda3/envs/myenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - xlsxwriter\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2023.7.22          |     pyhd8ed1ab_0         150 KB  conda-forge\n",
      "    openssl-3.1.4              |       h0d3ecfb_0         2.0 MB  conda-forge\n",
      "    xlsxwriter-3.1.9           |     pyhd8ed1ab_0         118 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  xlsxwriter         conda-forge/noarch::xlsxwriter-3.1.9-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl              pkgs/main::openssl-3.0.12-h1a28f6b_0 --> conda-forge::openssl-3.1.4-h0d3ecfb_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/osx-arm64::certifi-2023.7.2~ --> conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "xlsxwriter-3.1.9     | 118 KB    |                                       |   0% \n",
      "certifi-2023.7.22    | 150 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "openssl-3.1.4        | 2.0 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "certifi-2023.7.22    | 150 KB    | ###9                                  |  11% \u001b[A\n",
      "\n",
      "xlsxwriter-3.1.9     | 118 KB    | #####                                 |  14% \u001b[A\u001b[A\n",
      "xlsxwriter-3.1.9     | 118 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "openssl-3.1.4        | 2.0 MB    | #####9                                |  16% \u001b[A\u001b[A\n",
      "\n",
      "openssl-3.1.4        | 2.0 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "! echo \"y\" | conda install -c conda-forge xlsxwriter\n",
    "\n",
    "# Read CSV files into DataFrames\n",
    "df1 = pd.read_csv('1_sentiment_analysis_results_processed_less.csv')\n",
    "df2 = pd.read_csv('2_bert-base-multilingual-uncased-sentiment_processed_less.csv')\n",
    "df3 = pd.read_csv('3_lxyuan_distilbert_processed_less.csv')\n",
    "df4 = pd.read_csv('4_sohan_ai_sentiment_analysis_processed_less.csv')\n",
    "\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter('4_models_results_veryless.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    df1.to_excel(writer, sheet_name='Model_1', index=False)\n",
    "    df2.to_excel(writer, sheet_name='Model_2', index=False)\n",
    "    df3.to_excel(writer, sheet_name='Model_3', index=False)\n",
    "    df4.to_excel(writer, sheet_name='Model_4', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
