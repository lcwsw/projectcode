{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0ae379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages/huggingface_hub-0.19.0-py3.8.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nltk in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/ching/miniconda3/envs/myenv/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8e724a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ching/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/ching/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f621182",
   "metadata": {},
   "source": [
    "## Excluding Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbe855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "stars: 202\n",
      "great: 110\n",
      "phone: 102\n",
      "sound: 83\n",
      "good: 83\n",
      "speaker: 70\n",
      "gift: 64\n",
      "use: 48\n",
      "works: 47\n",
      "stand: 41\n",
      "\n",
      "Top Negative Keywords:\n",
      "stars: 135\n",
      "phone: 51\n",
      "sound: 42\n",
      "speaker: 37\n",
      "work: 29\n",
      "working: 27\n",
      "would: 26\n",
      "stopped: 24\n",
      "money: 23\n",
      "use: 22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"2_bert-base-multilingual-uncased-sentiment_processed_less.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter positive and negative reviews\n",
    "positive_reviews = df[df['Sentiment_Label'] > 2]['Preprocessed_Body']\n",
    "negative_reviews = df[df['Sentiment_Label'] < 2]['Preprocessed_Body']\n",
    "\n",
    "# Tokenization and stopwords removal\n",
    "def process_reviews(reviews):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews)\n",
    "negative_tokens = process_reviews(negative_reviews)\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Identify top keywords\n",
    "top_positive_keywords = positive_freq.most_common(10)\n",
    "top_negative_keywords = negative_freq.most_common(10)\n",
    "\n",
    "# Print Top Keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for keyword, frequency in top_positive_keywords:\n",
    "    print(f\"{keyword}: {frequency}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for keyword, frequency in top_negative_keywords:\n",
    "    print(f\"{keyword}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f16694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('stars', 'great'): 35\n",
      "('stars', 'good'): 22\n",
      "('sound', 'quality'): 18\n",
      "('good', 'sound'): 15\n",
      "('works', 'great'): 13\n",
      "('great', 'sound'): 13\n",
      "('stars', 'works'): 12\n",
      "('works', 'well'): 12\n",
      "('easy', 'use'): 11\n",
      "('battery', 'life'): 11\n",
      "\n",
      "Top Negative Keywords:\n",
      "('stopped', 'working'): 19\n",
      "('waste', 'money'): 11\n",
      "('money', 'stars'): 10\n",
      "('sound', 'quality'): 8\n",
      "('phone', 'stand'): 7\n",
      "('stars', 'stopped'): 7\n",
      "('stars', 'broke'): 7\n",
      "('stars', 'sound'): 6\n",
      "('working', 'months'): 6\n",
      "('stars', 'work'): 5\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    n_grams = list(ngrams(filtered_tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=2)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=2)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(10):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b1a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('good', 'sound', 'quality'): 6\n",
      "('stars', 'great', 'sound'): 6\n",
      "('stars', 'good', 'product'): 5\n",
      "('stars', 'works', 'great'): 5\n",
      "('stars', 'great', 'product'): 5\n",
      "('stars', 'great', 'gift'): 4\n",
      "('stars', 'good', 'value'): 4\n",
      "('nice', 'gift', 'stars'): 3\n",
      "('cell', 'phone', 'stand'): 3\n",
      "('father', 'day', 'gift'): 3\n",
      "('stars', 'husband', 'loves'): 3\n",
      "('stars', 'great', 'speaker'): 3\n",
      "('stars', 'bought', 'gift'): 3\n",
      "('product', 'would', 'recommend'): 3\n",
      "('stars', 'good', 'sound'): 3\n",
      "('easy', 'use', 'stars'): 3\n",
      "('good', 'value', 'money'): 3\n",
      "('stars', 'nice', 'little'): 2\n",
      "('jteman', 'cell', 'phone'): 2\n",
      "('cell', 'phone', 'holder'): 2\n",
      "\n",
      "Top Negative Keywords:\n",
      "('waste', 'money', 'stars'): 7\n",
      "('stars', 'stopped', 'working'): 7\n",
      "('stopped', 'working', 'months'): 6\n",
      "('cell', 'phone', 'stand'): 3\n",
      "('speaker', 'stopped', 'working'): 3\n",
      "('poor', 'sound', 'quality'): 3\n",
      "('loud', 'enough', 'stars'): 2\n",
      "('worth', 'money', 'stars'): 2\n",
      "('stars', 'good', 'good'): 2\n",
      "('phone', 'stars', 'sound'): 2\n",
      "('stars', 'sound', 'quality'): 2\n",
      "('stars', 'save', 'money'): 2\n",
      "('money', 'stars', 'bad'): 2\n",
      "('bluetooth', 'would', 'stay'): 2\n",
      "('would', 'stay', 'connected'): 2\n",
      "('stopped', 'producing', 'sound'): 2\n",
      "('used', 'times', 'product'): 2\n",
      "('father', 'day', 'gift'): 2\n",
      "('sound', 'lower', 'iphone'): 2\n",
      "('lower', 'iphone', 'speaker'): 2\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    filtered_tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    n_grams = list(ngrams(filtered_tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=3)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=3)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19aa1fd",
   "metadata": {},
   "source": [
    "## Including Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924fa282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Positive Keywords:\n",
      "('for', 'the', 'price'): 16\n",
      "('as', 'a', 'gift'): 14\n",
      "('this', 'for', 'my'): 12\n",
      "('easy', 'to', 'use'): 11\n",
      "('i', 'bought', 'this'): 11\n",
      "('the', 'sound', 'is'): 10\n",
      "('for', 'my', 'husband'): 10\n",
      "('this', 'was', 'a'): 9\n",
      "('gift', 'for', 'my'): 9\n",
      "('bought', 'this', 'for'): 9\n",
      "('in', 'the', 'kitchen'): 9\n",
      "('this', 'as', 'a'): 9\n",
      "('a', 'gift', 'for'): 9\n",
      "('the', 'sound', 'quality'): 8\n",
      "('this', 'is', 'a'): 7\n",
      "('i', 'use', 'it'): 7\n",
      "('he', 'loves', 'it'): 7\n",
      "('use', 'it', 'for'): 6\n",
      "('worth', 'the', 'money'): 6\n",
      "('stars', 'great', 'for'): 6\n",
      "\n",
      "Top Negative Keywords:\n",
      "('waste', 'of', 'money'): 9\n",
      "('stopped', 'working', 'after'): 9\n",
      "('it', 'stopped', 'working'): 7\n",
      "('doesn', 't', 'work'): 6\n",
      "('not', 'worth', 'it'): 6\n",
      "('working', 'after', 'months'): 6\n",
      "('stars', 'stopped', 'working'): 6\n",
      "('it', 'doesn', 't'): 5\n",
      "('of', 'money', 'stars'): 5\n",
      "('to', 'use', 'it'): 5\n",
      "('will', 'not', 'pair'): 5\n",
      "('not', 'worth', 'the'): 4\n",
      "('worth', 'the', 'money'): 4\n",
      "('to', 'listen', 'to'): 4\n",
      "('it', 'would', 'be'): 4\n",
      "('as', 'loud', 'as'): 4\n",
      "('to', 'return', 'it'): 4\n",
      "('not', 'pair', 'with'): 4\n",
      "('pair', 'with', 'my'): 4\n",
      "('i', 'have', 'no'): 4\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Function to process reviews\n",
    "def process_reviews(reviews, n=1):\n",
    "    tokens = [word.lower() for review in reviews for word in word_tokenize(str(review)) if word.isalpha()]\n",
    "    n_grams = list(ngrams(tokens, n))\n",
    "    return n_grams\n",
    "\n",
    "# Process positive and negative reviews\n",
    "positive_tokens = process_reviews(positive_reviews, n=3)  # Change n to the desired n-gram size\n",
    "negative_tokens = process_reviews(negative_reviews, n=3)  # Change n to the desired n-gram size\n",
    "\n",
    "# Frequency analysis\n",
    "positive_freq = Counter(positive_tokens)\n",
    "negative_freq = Counter(negative_tokens)\n",
    "\n",
    "# Display top positive and negative keywords\n",
    "print(\"Top Positive Keywords:\")\n",
    "for word, freq in positive_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nTop Negative Keywords:\")\n",
    "for word, freq in negative_freq.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0b7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551cde5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76eb740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
